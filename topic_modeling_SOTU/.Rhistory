sibs = mean(sub$sibs, na.rm = TRUE),
educ = mean(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = mean(sub$sibs, na.rm = TRUE),
educ = mean(sub$educ, na.rm = TRUE),
white = 0,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
mean(sub$sibs)
mean(sub$sibs, na.rm = TRUE)
summary(sub$sibs)
summary(sub$educ)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = mean(sub$sibs, na.rm = TRUE),
educ = min(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = mean(sub$sibs, na.rm = TRUE),
educ = max(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = 2,
educ = mean(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = 5,
educ = mean(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = mean(sub$age, na.rm = TRUE),
region = 1:9)
)
mean(sub$age, na.rm = T)
predict(zinb1, type = "response",
newdata = data.frame(
sibs = median(sub$sibs, na.rm = TRUE),
educ = median(sub$educ, na.rm = TRUE),
white = 1,
evermar = 1,
age = median(sub$age, na.rm = TRUE),
region = 1:9)
)
ROOT <- "http://higheredbcs.wiley.com/legacy/college/"
Lancaster <- read.table(paste0(ROOT, "lancaster/1405117206/datasets/Gasoline.txt"),
skip = 9, header = TRUE)
model_314 <- stan_glm(GASCON ~ PRICE + log(INCOME) + I(log(INCOME^2)), data = Lancaster,
chains = 4, family = gaussian, prior = student_t(df = 5, location = 0, scale = NULL))
library(rstanarm)
model_314 <- stan_glm(GASCON ~ PRICE + log(INCOME) + I(log(INCOME^2)), data = Lancaster,
chains = 4, family = gaussian, prior = student_t(df = 5, location = 0, scale = NULL))
model_314 <- stan_glm(GASCON ~ PRICE + log(INCOME) + I(log(INCOME^2)), data = Lancaster,
chains = 4, iterations = 100, family = gaussian, prior = student_t(df = 5, location = 0, scale = NULL))
?cauchy
log(0.29)
log(0.25)
log(0.21)
log(0.24)
count_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_relation <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_power <- as.matrix(count_power)
count_relation <- as.matrix(count_relation)
unweight <- count_power * count_relation
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
set.seed(12345)
l <- layout.kamada.kawai(unweight_graph)
library(igraph)
set.seed(12345)
l <- layout.kamada.kawai(unweight_graph)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
set.seed(12345)
l <- layout.kamada.kawai(unweight_graph)
# Plot undecorated first.
par(mfrow=c(1,1))
oldMargins<-par("mar")
par(mar=c(1,1,1,1))
### par(mar=oldMargins) ### to return to default ...
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
count_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_power <- as.matrix(count_power)
unweight <- count_power * count_relation
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
set.seed(12345)
l <- layout.kamada.kawai(unweight_graph)
# Plot undecorated first.
par(mfrow=c(1,1))
oldMargins<-par("mar")
par(mar=c(1,1,1,1))
### par(mar=oldMargins) ### to return to default ...
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
count_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
is.na(count_power[3])
count_relation <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_power <- as.matrix(count_power)
count_relation <- as.matrix(count_relation)
unweight <- count_power * count_relation
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
set.seed(12345)
l <- layout.kamada.kawai(unweight_graph)
# Plot undecorated first.
par(mfrow=c(1,1))
oldMargins<-par("mar")
par(mar=c(1,1,1,1))
### par(mar=oldMargins) ### to return to default ...
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = FALSE)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = NULL)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
weight_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
weight_relation <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
weight_power <- as.matrix(weight_power)
weight_relation <- as.matrix(weight_relation)
weight <- weight_power * weight_relation
weight_graph <- graph.adjacency(weight, mode="undirected", weighted = NULL)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
e(unweight_graph)
E(unweight_graph)
?degree
V(unweight_graph)$size <- 4*sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- log(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- 4*sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- 10*sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = NULL)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- 10*sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
bad_vs <- V(unweight_graph)[degree(unweight_graph) < 2]
unweight_graph <- delete.vertices(unweight_graph, bad_vs)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
set.seed(123)
l <- layout.kamada.kawai(unweight_graph)
bad_vs <- V(unweight_graph)[degree(unweight_graph) < 2]
unweight_graph <- delete.vertices(unweight_graph, bad_vs)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
View(count_relation)
```{r}
library(igraph)
count_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_relation <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
count_power <- as.matrix(count_power)
count_relation <- as.matrix(count_relation)
unweight <- count_power
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = NULL)
set.seed(123)
count_power <- as.matrix(count_power)
count_relation <- as.matrix(count_relation)
unweight <- count_power
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = NULL)
set.seed(123)
bad_vs <- V(unweight_graph)[degree(unweight_graph) < 1]
unweight_graph <- delete.vertices(unweight_graph, bad_vs)
V(unweight_graph)$size <- sqrt(degree(count_relation, mode="total"))
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
count_power <- as.matrix(count_power)
count_relation <- as.matrix(count_relation)
unweight <- count_power * count_relation
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = NULL)
set.seed(123)
bad_vs <- V(unweight_graph)[degree(unweight_graph) < 2]
unweight_graph <- delete.vertices(unweight_graph, bad_vs)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
# Shrink arrows
plot(unweight_graph, layout=l, edge.arrow.size=.3)
View(count_relation)
unweight_graph <- graph.adjacency(unweight, mode="undirected", weighted = TRUE)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
unweight_graph <- graph.adjacency(unweight, mode="directed", weighted = TRUE)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
V(unweight_graph)$size <- sqrt(degree(unweight_graph, mode="total"))
plot(unweight_graph, layout=l, edge.arrow.size=.3)
unweight_graph <- graph.adjacency(unweight, mode="directed", weighted = TRUE)
plot(unweight_graph, layout=l, edge.arrow.size=.3)
wd
?wd
pwd
?pwd
binary_count <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
density(binary_count)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
density(binary_graph)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = NULL)
as.matrix(binary_count)
binary_count <- as.matrix(binary_count)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = NULL)
density(binary_graph)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
density(binary_graph)
?density
library(igraph)
density(binary_graph)
library(sna)
install.packages("sna")
install.packages(network)
install.packages("network")
library(network)
network.density(binary_graph)
is.network(binary_graph)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
is.network(binary_graph)
graph.density(binary_count)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
graph.density(binary_count)
binary_count <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
binary_count <- as.matrix(binary_count)
binary_graph <- graph.adjacency(binary_count, mode="undirected", weighted = TRUE)
graph.density(binary_graph)
degree(binary_graph)
mean(degree(binary_graph))
degree <- degree(binary_graph)
summary(degree)
library(psych)
describe(degree)
cov <- 2.3/1.92
cov
degree(binary_graph)
btwn <- betweenness(binary_graph,  directed = F)
btwn
eigen <- evcent(binary_graph)
eigen
close <- closeness(binary_graph, mode = c("all"))
close
eigen
cor(btwn, close, eigen)
cor(btwn, eigen)
weight_power <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
weight_relation <- read.csv(file.choose(), header = TRUE, row.names = 1, check.names = TRUE)
weight_power <- as.matrix(weight_power)
weight_relation <- as.matrix(weight_relation)
weight <- weight_power * weight_relation
weight_graph <- graph.adjacency(weight, mode="directed", weighted = TRUE)
library(igraph)
weight_graph <- graph.adjacency(weight, mode="directed", weighted = TRUE)
set.seed(123)
?degree
degree(weight_graph, mode = "in", loops = FALSE)
view(weight_graph)
View(weight)
plot(weight_graph)
out_degree <- degree(weight_graph, mode = "out", loops = FALSE)
out_degree
View(weight_power)
stopifnot(require(brms))
install.packages("brms", lib)
library(brms)
install.packages("brms", lib)
library(brms)
install.packages("quanteda")
install.packages(‘topicmodels’)
install.packages("topicmodels")
library(topicmodels)
setwd("~/Desktop/portfolio/topic_modelling")
library(tm)
library(SnowballC)
install.packages("Rcampdf", repos = "http://datacube.wu.ac.at/", type = "source")
cname <- file.path("~", "topic_modelling", "texts")
cname
dir(cname)
cname <- file.path("~", "Desktop/portfolio/topic_modelling", "texts")
cname
dir(cname)
cname
dir(cname)
cname <- file.path("~", "Desktop/portfolio/topic_modelling", "texts")
cname
dir(cname)
docs <- Corpus(DirSource(cname))
setwd("~/Desktop/portfolio/topic_modelling")
cname <- file.path("~", "Desktop/portfolio/topic_modelling", "texts")
cname
dir(cname)
docs <- Corpus(DirSource(cname))
setwd("~/Desktop/portfolio/topic_modelling")
cname <- file.path("~", "Desktop/portfolio/topic_modelling", "texts")
cname
dir(cname)
library(tm)
library(SnowballC)
library(Rcampdf)
setwd("~/Desktop/portfolio/topic_modelling")
cname <- file.path("~", "Desktop/portfolio/topic_modelling", "texts")
cname
dir(cname)
docs <- Corpus(DirSource(cname))
library(quanteda)
docs <- textfile("~/Desktop/portfolio/topic_modelling/*.txt", cache = FALSE)
summary(corpus(docs), 5)
library(topicmodels)
?dfm
dfm_docs <- dfm(docs)
docs <- textfile("~/Desktop/portfolio/topic_modelling/*.txt", cache = FALSE)
summary(corpus(docs), 5)
dfm_docs <- dfm(docs)
docs_corpus <- corpus(docs)
dfm_docs <- dfm(docs_corpus)
dfmtrim_docs <- dfmTrim(dfm_docs, minCount = 25, minDoc = 3)
?dfmTrim
??dfmTrim
?tf-idf
?dfm
docs <- textfile("~/Desktop/portfolio/topic_modelling/*.txt", cache = FALSE)
summary(corpus(docs), 5)
docs_corpus <- corpus(docs)
dfm_docs <- dfm(docs_corpus, stem = TRUE)
data(custom_stopwords)
data(stopwords)
final_docs <- stopwordsRemove(dfmtrim_docs, stopwords)
dfm_docs <- dfm(docs_corpus, stem = TRUE, ignoredFeatures=c(stopwords("english")))
docs <- textfile("~/Desktop/portfolio/topic_modelling/*.txt", cache = FALSE)
summary(corpus(docs), 5)
docs_corpus <- corpus(docs)
dfm_docs <- dfm(docs_corpus, stem = TRUE, ignoredFeatures=c(stopwords("english")))
dim(dfm_docs)
library(lsa)
install.packages("lsa")
cosine(dfm_docs)
stopifnot(require(lsa))
cosine(dfm_docs)
cor(dfm_docs)
cor(docs_corpus)
cor(as.matrix(docs_corpus))
cor(as.matrix(dfm_docs))
cosine(as.matrix(dfm_docs))
cosine(as.matrix(docs_corpus))
cosine(as.matrix(docs))
ctable <- table(dfm_docs)
ctable <- table(docs_corpus)
dfm_docs <- dfm_docs[which(rowSums(dfm_docs) > 0),]
triplet_dfm_docs<- dfm2tmformat(dfm_docs)
topfeatures(dfm_docs, 10)
dfm_docs <- dfm(docs_corpus, stem = TRUE, ignoredFeatures=c("will", "year", stopwords("english")))
dim(dfm_docs)
topfeatures(dfm_docs, 25)
dfm_docs <- dfm(docs_corpus, stem = TRUE, ignoredFeatures=c("will", stopwords("english")))
dim(dfm_docs)
topfeatures(dfm_docs, 25)
kwic(docs_corpus, "help", 5)
kwic(docs_corpus, "help", 1)
kwic(docs_corpus, "help", 5)
?kwic
kwic(docs_corpus, "help", window = 5)
kwic(docs_corpus, "help", window = 5, valuetype = "glob")
kwic(docs_corpus, "help", window = 5, valuetype = "regex")
kwic(docs_corpus, "help", window = 5, valuetype = "fixed")
kwic(docs_corpus, "help", window = 5)
kwic(docs_corpus, "help", window = 10)
kwic(docs_corpus, "help", window = 5)
plot(mydfm, min.freq = 6, random.order = FALSE)
plot(dfm_docs, min.freq = 6, random.order = FALSE)
topfeatures(dfm_docs, 25)
plot(docs_corpus, min.freq = 200, random.order = FALSE)
plot(docs_corpus, min.freq = 200, random.order = FALSE)
plot(dfm_docs, min.freq = 200, random.order = FALSE)
dfm_docs <- dfm(docs_corpus, ignoredFeatures=c("will", stopwords("english")))
dim(dfm_docs)
topfeatures(dfm_docs, 25)
kwic(docs_corpus, "help", window = 5)
plot(dfm_docs, min.freq = 200, random.order = FALSE)
plot(dfm_docs, min.freq = 250, random.order = FALSE)
plot(dfm_docs, min.freq = 250, random.order = FALSE)
plot(dfm_docs, min.freq = 200, random.order = FALSE)
plot(dfm_docs, min.freq = 150, random.order = FALSE)
library(wordcloud)
wordcloud(d$word,d$freq, scale=c(8,.3),min.freq=2,max.words=100, random.order=T, rot.per=.15, colors=pal, vfont=c("sans serif","plain"))
pal <- brewer.pal(9, "BuGn")
pal <- pal[-(1:2)]
wordcloud(d$word,d$freq, scale=c(8,.3),min.freq=2,max.words=100, random.order=T, rot.per=.15, colors=pal, vfont=c("sans serif","plain"))
plot(dfm_docs, min.freq = 100, random.order = FALSE)
warnings()
plot(dfm_docs, min.freq = 150, random.order = FALSE)
plot(dfm_docs, min.freq = 125, random.order = FALSE)
topfeatures(dfm_docs, 25)
stopifnot(require(colorBrewer))
install.packages("colorBrewer")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
stopifnot(require(RColorBrewer))
plot(dfm_docs, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(8, .5))
plot(dfm_docs, min.freq = 150, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(8, .5))
plot(dfm_docs, min.freq = 150, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(10, .5))
plot(dfm_docs, min.freq = 150, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(3, .5))
plot(dfm_docs, min.freq = 100, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(3, .5))
plot(dfm_docs, min.freq = 100, max.words = 150, colors = brewer.pal(6, "Dark2"), scale = c(3, .5))
set.seed(1234)
plot(dfm_docs, min.freq = 100, max.words = 150, colors = brewer.pal(6, "Dark2"), scale = c(3, .5))
plot(dfm_docs, min.freq = 100, max.words = 150, colors = brewer.pal(6, "Dark2"), scale = c(3, .5), random.order = FALSE)
plot(dfm_docs, min.freq = 100, max.words = 100, colors = brewer.pal(6, "Dark2"), scale = c(3, .5), random.order = FALSE)
topfeatures(dfm_docs, 25)
?dfm
quant_dfm <- dfm(docs_corpus, ignoredFeatures=c("will", stopwords("english")), stem = TRUE, verbose = FALSE)
stopifnot(require(topicmodels))
if (require(topicmodels)) {
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 25)
get_terms(fit, 5)
topics(fit, 3)
}
terms
terms(lda)
lda <- if (require(topicmodels)) {
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 25)
get_terms(fit, 5)
topics(fit, 3)
}
terms(lda, 5)
terms(lda)
fit
topics
summary(fit)
print(fit)
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 25)
get_terms(fit, 5)
topics(fit, 3)
get_terms(fit, 5)
topics(fit, 3)
get_terms(fit, 5)
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 10)
get_terms(fit, 5)
topics(fit, 3)
set.seed(1234)
set.seed(1234)
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 10)
most_frequent <- which.max(tabulate(fit))
most_frequent <- which.max(tabulate(terms))
sapply(fit, function(x)
mean(apply(posterior(x)$topics,
1, function(z) - sum(z * log(z)))))
sapply(fit, function(x)
mean(apply(posterior(x)$topics,
1, function(z) - sum(z * log(z)))))
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 10)
terms <- get_terms(fit, 5)
topic<- topics(fit, 3)
most_frequent <- which.max(tabulate(topic))
most_frequent
terms
terms <- get_terms(fit, 5)
terms
fit <- LDA(convert(quant_dfm, to = "topicmodels"), k = 25)
terms <- get_terms(fit, 5)
terms
topics
topic<- topics(fit, 3)
topics
topic<- topics(fit, 3)
topic
most_frequent <- which.max(tabulate(topic))
most_frequent
terms
terms2 <- get_terms(fit, 10)
terms2
terms
